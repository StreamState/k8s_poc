apiVersion: argoproj.io/v1alpha1
kind: Sensor
metadata:
  name: deploystreamstateapi
  namespace: {{ .Values.namespaces.controlpanenamespace }}
spec:
  template:
    serviceAccountName: argo-events-sa 
  dependencies:
    - name: deploypysparkjob
      eventSourceName: streamstatewebservice
      eventName: deploy
  triggers:
    - template:
        name: webhook-workflow-trigger
        k8s:
          group: argoproj.io
          version: v1alpha1
          resource: workflows
          operation: create
          source:
            resource:
              apiVersion: argoproj.io/v1alpha1
              kind: Workflow
              metadata:
                generateName: streamstate-  # Name of this Workflow
              spec:
                serviceAccountName: {{ .Values.serviceaccounts.argo_service_account.name }}  
                arguments:
                  parameters:
                    - name: pythoncode
                      value: hello world # this should be overridden
                    - name: inputs
                      value: |
                        [{"topic":"sometopic"}] # this should be overridden
                    - name: assertions
                      value: hello world # this should be overridden
                    - name: kafka
                      value: hello world # this should be overridden
                    - name: outputs
                      value: hello world # this should be overridden
                    - name: table
                      value: hello world # this should be overridden
                    - name: appname
                      value: hello world
                entrypoint: main     
                volumeClaimTemplates:
                - metadata:
                    name: work
                  spec:
                    accessModes: [ "ReadWriteOnce" ]
                    resources:
                      requests:
                        storage: 64Mi
                templates:
                - name: main
                  inputs:
                    parameters:
                      - name: pythoncode
                      - name: inputs
                      - name: assertions
                      - name: kafka
                      - name: outputs
                      - name: table
                      - name: appname
                  dag:
                    tasks:
                    - name: runmypy
                      template: mypy
                      arguments:
                        parameters: 
                         - name: pythoncode
                           value: "{{ `{{inputs.parameters.pythoncode}}` }}"
                         
                    - name: rununittests
                      template: unittests
                      arguments:
                        parameters: 
                         - name: pythoncode
                           value: "{{ `{{inputs.parameters.pythoncode}}` }}"
                         - name: inputs
                           value: "{{ `{{inputs.parameters.inputs}}` }}"
                         - name: assertions
                           value: "{{ `{{inputs.parameters.assertions}}` }}"

                    - name: runfirestoresetup 
                      template: firestoresetup
                      arguments:
                        parameters:
                         - name: appname
                           value: "{{ `{{inputs.parameters.appname}}` }}"
                         - name: table
                           value: "{{ `{{inputs.parameters.table}}` }}"
                      dependencies: [runmypy, rununittests]

                    - name: setupconfluent
                      template: confluenttopiccreate
                      arguments:
                        parameters:
                          - name: appname
                            value: "{{ `{{inputs.parameters.appname}}` }}"
                          - name: kafka
                            value: "{{ `{{inputs.parameters.kafka}}` }}"
                          - name: version
                            value: "{{ `{{tasks.runfirestoresetup.outputs.result}}` }}"
                      dependencies: [runfirestoresetup]

                    - name: builddocker
                      template: create-docker-file
                      arguments:
                        parameters:
                         - name: pythoncode
                           value: "{{ `{{inputs.parameters.pythoncode}}` }}"

                      dependencies: [runmypy, rununittests]

                    - name: deploydocker 
                      template: build-docker-image
                      arguments:
                        parameters:
                         - name: version
                           value: "{{ `{{tasks.runfirestoresetup.outputs.result}}` }}"
                         - name: appname
                           value: "{{ `{{inputs.parameters.appname}}` }}"
                      dependencies: [builddocker, runfirestoresetup]

                   
                    - name: createfolder
                      template: gcsfolder
                      arguments:
                        parameters: 
                          - name: appname
                            value: "{{ `{{inputs.parameters.appname}}` }}"
                          - name: inputs
                            value: "{{ `{{inputs.parameters.inputs}}` }}"

                      dependencies: [runmypy, rununittests]

                    - name:  runsparkpersist
                      template: sparksubmittopic
                      arguments:
                        parameters: 
                          - name: pythoncode
                            value: "{{ `{{inputs.parameters.pythoncode}}` }}"
                          - name: input
                            value: "{{ `{{item}}` }}"
                          - name: table
                            value: "{{ `{{inputs.parameters.table}}` }}"
                          - name: topic
                            value: "{{ `{{item.topic}}` }}" # loop from withParam
                          - name: kafka
                            value: "{{ `{{inputs.parameters.kafka}}` }}"
                          - name: outputs
                            value: "{{ `{{inputs.parameters.outputs}}` }}"
                          - name: appname
                            value: "{{ `{{inputs.parameters.appname}}` }}"
                          - name: version
                            value: "{{ `{{tasks.runfirestoresetup.outputs.result}}` }}"
                      dependencies: 
                        - createfolder
                        - deploydocker
                        - runfirestoresetup
                      withParam: "{{ `{{inputs.parameters.inputs}}` }}" # loops through
                    
                    - name: runsparkmainapp
                      template: sparksubmitmain
                      arguments:
                        parameters: 
                          - name: pythoncode
                            value: "{{ `{{inputs.parameters.pythoncode}}` }}"
                          - name: inputs
                            value: "{{ `{{inputs.parameters.inputs}}` }}"
                          - name: kafka
                            value: "{{ `{{inputs.parameters.kafka}}` }}"
                          - name: outputs
                            value: "{{ `{{inputs.parameters.outputs}}` }}"
                          - name: appname
                            value: "{{ `{{inputs.parameters.appname}}` }}"
                          - name: version
                            value: "{{ `{{tasks.runfirestoresetup.outputs.result}}` }}"
                          - name: table
                            value: "{{ `{{inputs.parameters.table}}` }}"
                      dependencies: 
                        - createfolder
                        - deploydocker
                        - runfirestoresetup
                        - setupconfluent
                      
                - name: mypy
                  inputs:
                    parameters:
                      - name: pythoncode
                  container:
                    image: cytopia/mypy 
                    command: [sh, -c]
                    args: 
                      - |
                        echo "{{ `{{inputs.parameters.pythoncode}}` }}" | base64 --decode > process.py
                        mypy process.py --ignore-missing-imports
                    
                - name: unittests
                  inputs:
                    parameters:
                      - name: pythoncode
                      - name: inputs
                      - name: assertions
                  container:
                    image: {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.project }}/pysparktest:{{ .Values.dockerTag }}
                    imagePullPolicy: Always
                    command: [sh, -c]
                    args: 
                      - |
                        echo "{{ `{{inputs.parameters.pythoncode}}` }}" | base64 --decode > process.py
                        echo "{{ `{{inputs.parameters.inputs}}` }}" > sampleinputs.json
                        echo "{{ `{{inputs.parameters.assertions}}` }}" > assertedoutputs.json
                        run-test '/opt/spark/work-dir/' sampleinputs.json assertedoutputs.json


                - name: gcsfolder
                  serviceAccountName: {{ .Values.serviceaccounts.argo_service_account.name }}
                  inputs:
                    parameters:
                      - name: appname
                      - name: inputs
                  resource:
                    action: create
                    successCondition: status.succeeded > 0
                    failureCondition: status.failed > 1
                    manifest: |
                      apiVersion: batch/v1
                      kind: Job
                      metadata:
                        generateName: gcsfolder-
                        namespace: {{ .Values.namespaces.sparknamespace }}
                      spec:
                        template:
                          spec:
                            serviceAccountName: {{ .Values.serviceaccounts.spark_service_account.name }}
                            containers:
                            - name: gcsfolder
                              image: {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.project }}/pysparkbase:{{ .Values.dockerTag }}
                              imagePullPolicy: Always
                              command: [
                                "python3",  
                                "create_folder.py", 
                                "{{ `{{inputs.parameters.appname}}` }}", 
                                "streamstate-sparkstorage-{{ .Values.organization }}", 
                                "{{ `{{inputs.parameters.inputs}}` }}"
                              ]
                            restartPolicy: Never
                        # backoffLimit: 4
                
                - name: create-docker-file
                  inputs:
                    parameters:
                      - name: pythoncode
                      - name: dockerfileline1 
                        value: FROM {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.project }}/pysparkbase:{{ .Values.dockerTag }}
                      - name: dockerfileline2 
                        value: COPY process.py /opt/spark/work-dir/process.py
                  container:
                    image: cytopia/mypy # doesn't really matter, so may as well use an image already downloaded
                    imagePullPolicy: IfNotPresent
                    command: [sh, -c]
                    args:
                      - | 
                        echo "{{ `{{inputs.parameters.pythoncode}}` }}" | base64 -d > /work/process.py
                        echo "{{ `{{inputs.parameters.dockerfileline1}}` }}" > /work/Final.Dockerfile
                        echo "{{ `{{inputs.parameters.dockerfileline2}}` }}" >> /work/Final.Dockerfile
                        cat /work/process.py
                      
                    workingDir: /work
                    volumeMounts:
                    - mountPath: /work 
                      name: work
                
                - name: build-docker-image
                  inputs:
                    parameters:
                      # (Base) name of the image to push
                      - name: image
                        value:  {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.registry }}
                      - name: appname
                      - name: version
                  serviceAccountName: {{ .Values.serviceaccounts.docker_secret_write_service_account.name }}
                  container:
                    image: gcr.io/kaniko-project/executor:latest
                    args:
                    - "--dockerfile=/work/Final.Dockerfile"
                    - "--context=dir:///work"
                    - "--destination={{ `{{inputs.parameters.image}}` }}/{{ `{{inputs.parameters.appname}}` }}:v{{ `{{inputs.parameters.version}}` }}"
                    workingDir: /work
                    volumeMounts:
                    - mountPath: /work 
                      name: work

                - name: firestoresetup 
                  serviceAccountName: {{ .Values.serviceaccounts.firestore_service_account.name }}
                  inputs:
                    parameters:
                      - name: table
                      - name: appname
                  script: # script allows us to get the output from the console rather than from a file
                    image: {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.project }}/firestoresetup:{{ .Values.dockerTag }}
                    imagePullPolicy: Always
                    envFrom:
                    - configMapRef:
                        name: {{ .Values.dataconfigargo }}
                    command: [sh]
                    source: | 
                      python3 entrypoint.py "{{ `{{inputs.parameters.appname}}` }}" "{{ `{{inputs.parameters.table}}` }}"

                - name: confluenttopiccreate 
                  inputs:
                    parameters:
                      - name: appname
                      - name: kafka
                      - name: version
                  container: 
                    image:  {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.project }}/firestoresetup:{{ .Values.dockerTag }}
                    imagePullPolicy: Always
                    command: [
                      "python3",
                      "provision_confluent_kafka.py",
                      "{{ `{{inputs.parameters.appname}}` }}", 
                      "{{ `{{inputs.parameters.kafka}}` }}",
                      "{{ `{{inputs.parameters.version}}` }}"
                    ] 
                
                - name: sparksubmitmain
                  serviceAccountName: {{ .Values.serviceaccounts.argo_service_account.name }}
                  inputs:
                    parameters:
                      - name: inputs
                      - name: table
                      - name: kafka
                      - name: outputs
                      - name: appname
                      - name: version
  
                  resource:                   # indicates that this is a resource template
                    action: apply            # can be any kubectl action (e.g. create, delete, apply, patch)
                    # The successCondition and failureCondition are optional expressions.
                    # If failureCondition is true, the step is considered failed.
                    # If successCondition is true, the step is considered successful.
                    # They use kubernetes label selection syntax and can be applied against any field
                    # of the resource (not just labels). Multiple AND conditions can be represented by comma
                    # delimited expressions.
                    # For more details: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
                    successCondition: status.applicationState.state == RUNNING # status.succeeded > 0
                    failureCondition: status.applicationState.state == FAILING
                    manifest: |               #put your kubernetes spec here
                      apiVersion: "sparkoperator.k8s.io/v1beta2"
                      kind: SparkApplication
                      metadata:
                        name: "{{ `{{inputs.parameters.appname}}` }}-main"
                        namespace: {{ .Values.namespaces.sparknamespace }}
                        labels:
                          app: "{{ `{{inputs.parameters.appname}}` }}"
                      spec:
                        sparkConf:
                          spark.eventLog.enabled: "true" # spark history
                          spark.eventLog.dir: gs://{{ .Values.buckets.bucket_without_gs}}/{{ .Values.spark_history_name }}
                          spark.sql.streaming.metricsEnabled: "true"
                          spark.ui.prometheus.enabled: "true"
                          spark.hadoop.fs.gs.project.id: {{ .Values.project }} 
                          spark.hadoop.gs.system.bucket: {{ .Values.buckets.bucket_without_gs }}   
                          spark.hadoop.google.cloud.auth.service.account.enable: "true" 
                          spark.hadoop.fs.gs.impl: "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"
                          spark.hadoop.fs.AbstractFileSystem.gs.impl: "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS"
                          spark.metrics.conf.*.sink.prometheusServlet.class: org.apache.spark.metrics.sink.PrometheusServlet
                          spark.metrics.conf.*.sink.prometheusServlet.path: /metrics/prometheus
                          spark.metrics.conf.master.sink.prometheusServlet.path: /metrics/master/prometheus
                          spark.metrics.conf.applications.sink.prometheusServlet.path: /metrics/applications/prometheus
                        
                        type: Python
                        pythonVersion: "3"
                        mode: cluster
                        image: {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.registry }}/{{ `{{inputs.parameters.appname}}` }}:v{{ `{{inputs.parameters.version}}` }}

                        imagePullPolicy: Always
                        mainApplicationFile: "local:///opt/spark/work-dir/main_app.py" # todo, adjust this to be the right entrypoint
                        sparkVersion: "3.1.1"
                        
                        arguments:
                          - "{{ `{{inputs.parameters.appname}}` }}"
                          - gs://{{ .Values.buckets.bucket_without_gs }}'
                          - "{{ `{{inputs.parameters.table}}` }}"
                          - "{{ `{{inputs.parameters.outputs}}` }}"
                          - "{{ `{{inputs.parameters.kafka}}` }}"
                          - "{{ `{{inputs.parameters.inputs}}` }}"
                          - 'checkpoint'
                          - "{{ `{{inputs.parameters.version}}` }}"
                       
                        restartPolicy:
                          type: Always # should be able to resume from checkpoint if killed for some reason
                        driver:
                          coreRequest: 200m
                          memory: "512m"
                          serviceAccount: {{ .Values.serviceaccounts.spark_service_account.name }} # this maps to spark-gcs 
                          labels:
                            metrics-exposed: "true"
                        executor:
                          instances: 1
                          cores: 1
                          memory: "512m"
                          serviceAccount: {{ .Values.serviceaccounts.spark_service_account.name }} # this maps to spark-gcs
                          labels:
                            metrics-exposed: "true"  

                - name: sparksubmittopic
                  serviceAccountName: {{ .Values.serviceaccounts.argo_service_account.name }}
                  inputs:
                    parameters:
                      - name: input
                      - name: topic
                      - name: kafka
                      - name: outputs
                      - name: appname
                      - name: version
  
                  resource:                   # indicates that this is a resource template
                    action: apply            # can be any kubectl action (e.g. create, delete, apply, patch)
                    # The successCondition and failureCondition are optional expressions.
                    # If failureCondition is true, the step is considered failed.
                    # If successCondition is true, the step is considered successful.
                    # They use kubernetes label selection syntax and can be applied against any field
                    # of the resource (not just labels). Multiple AND conditions can be represented by comma
                    # delimited expressions.
                    # For more details: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/
                    # # sprig is not allowed until 3.1 name: {{ "{{inputs.parameters.appname}}" }}-{{ "{{=sprig.replace(inputs.parameters.topic, \"_\", \"-\")}}" }}-persist 
                    successCondition: status.applicationState.state == RUNNING # status.succeeded > 0
                    failureCondition: status.applicationState.state == FAILING
                    manifest: |               #put your kubernetes spec here
                      apiVersion: "sparkoperator.k8s.io/v1beta2"
                      kind: SparkApplication
                      metadata:
                        name: "{{ `{{inputs.parameters.appname}}` }}-placeholdertopicname-persist" # update this once 3.1 is released
                        namespace: {{ .Values.namespaces.sparknamespace }}
                        labels:
                          app: "{{ `{{inputs.parameters.appname}}` }}"
                      spec:
                        sparkConf:
                          spark.eventLog.enabled: "true" # spark history
                          spark.eventLog.dir: gs://{{ .Values.buckets.bucket_without_gs}}/{{ .Values.spark_history_name }}
                          spark.sql.streaming.metricsEnabled: "true"
                          spark.ui.prometheus.enabled: "true"
                          spark.hadoop.fs.gs.project.id: {{ .Values.project }}
                          spark.hadoop.gs.system.bucket: {{ .Values.buckets.bucket_without_gs }}
                          spark.hadoop.google.cloud.auth.service.account.enable: "true" 
                          spark.hadoop.fs.gs.impl: "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem"
                          spark.hadoop.fs.AbstractFileSystem.gs.impl: "com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS"
                          spark.metrics.conf.*.sink.prometheusServlet.class: org.apache.spark.metrics.sink.PrometheusServlet
                          spark.metrics.conf.*.sink.prometheusServlet.path: /metrics/prometheus
                          spark.metrics.conf.master.sink.prometheusServlet.path: /metrics/master/prometheus
                          spark.metrics.conf.applications.sink.prometheusServlet.path: /metrics/applications/prometheus
                        
                        type: Python
                        pythonVersion: "3"
                        mode: cluster
                        image: {{ .Values.registryprefix }}/{{ .Values.project }}/{{ .Values.registry }}/{{ "{{inputs.parameters.appname}}" }}:v{{ "{{inputs.parameters.version}}" }}
                        imagePullPolicy: Always
                        mainApplicationFile: "local:///opt/spark/work-dir/persist_app.py" # todo, adjust this to be the right entrypoint
                        sparkVersion: "3.1.1"
                        
                        arguments:
                          - "{{ `{{inputs.parameters.appname}}` }}-{{ `{{inputs.parameters.topic}}` }}-persist"
                          - 'gs://{{ .Values.buckets.bucket_without_gs }}'
                          - "{{ `{{inputs.parameters.outputs}}` }}"
                          - "{{ `{{inputs.parameters.kafka}}` }}"
                          - "{{ `{{inputs.parameters.input}}` }}"
                          - 'checkpoint'
                       
                        restartPolicy:
                          type: Always # should be able to resume from checkpoint if killed for some reason
                        driver:
                          coreRequest: 200m
                          memory: "512m"
                          serviceAccount: {{ .Values.serviceaccounts.spark_service_account.name }} # this maps to spark-gcs 
                          labels:
                            metrics-exposed: "true"
                        executor:
                          instances: 1
                          cores: 1
                          memory: "512m"
                          serviceAccount: {{ .Values.serviceaccounts.spark_service_account.name }} # this maps to spark-gcs
                          labels:
                            metrics-exposed: "true"

          parameters:
            - src:
                dependencyName: deploypysparkjob
                dataKey: body.pythoncode # base 64 python code
              dest: spec.arguments.parameters.0.value
            - src:
                dependencyName: deploypysparkjob
                dataKey: body.inputs # list of topic, schema (fields: list), sample (list of inputs, eg [{"field1": "hello"}])
              dest: spec.arguments.parameters.1.value
            - src:
                dependencyName: deploypysparkjob
                dataKey: body.assertions # list of expected (eg, [{"field1: "hello", "field2":"hi"}])
              dest: spec.arguments.parameters.2.value
            - src:
                dependencyName: deploypysparkjob
                dataKey: body.kafka #brokers, as string (more to come....)
              dest: spec.arguments.parameters.3.value
            - src:
                dependencyName: deploypysparkjob
                dataKey: body.outputs # mode, checkpoint_location, output_name (which is probably just app name?)
              dest: spec.arguments.parameters.4.value
            - src:
                dependencyName: deploypysparkjob
                dataKey: body.table # primary_keys: list, output_schema: avro
              dest: spec.arguments.parameters.5.value
            - src:
                dependencyName: deploypysparkjob # could this come from output schema's name?  eg, [outputschema.name]-dev-app?
                dataKey: body.appname # string
              dest: spec.arguments.parameters.6.value