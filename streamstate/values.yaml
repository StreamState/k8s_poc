# Default values for streamstate.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: nginx
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

nameOverride: "streamstate"
fullnameOverride: "streamstate-chart"

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "streamstate-sa"

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

namespaces:
  controlpanenamespace: "${controlpanenamespace}" # hacky, but need something like https://github.com/helm/helm/pull/6876 to make it not hacky...
  sparknamespace: "${sparknamespace}" 

organization: "${organization}"
project: "${project}"
dockerTag: "${tag}"
registryprefix: us-central1-docker.pkg.dev
registry: ${registry}
serviceaccounts:
  sparkhistoryserviceaccount: "${sparkhistoryserviceaccount}"
  argoserviceaccount: ${argoserviceaccount}
  sparkserviceaccount: ${sparkserviceaccount}
  dockersecretwrite: ${dockersecretwrite}
  firestoreserviceaccount : ${firestoreserviceaccount}

buckets:
  bucket_without_gs: ${bucket_without_gs}
  #spark_storage_bucket_url: ${spark_storage_bucket_url}

# make sure to pass this in to kubernetes config map,
# see line 505 of kuberentes.tf
dataconfigargo: sparkjobdata # careful, this same name shows up in both namespaces
sparkhistoryname: ${sparkhistoryname}

kube-prometheus-stack:
  kube-state-metrics:
    extraArgs:
      - --metric-labels-allowlist=pods=[spark-role,sparkoperator.k8s.io/app-name,sparkoperator.k8s.io/launched-by-spark-operator]
  alertmanager:
    enabled: false
    useClusterRole: false

  grafana:
    enabled: false

  prometheus-operator:
    namespaces:
      releaseNamespace: true
      additional:
        - "${sparknamespace}"

  kubeDns:
    enabled: true

  coreDns:
    enabled: false

  prometheus:
    prometheusSpec:
      # blank since "monitoring" prefix will be stripped by nginx
      routePrefix: / # https://prometheus.io/docs/guides/tls-encryption/
      externalUrl: https://${organization}.streamstate.org/monitoring # see https://blog.cubieserver.de/2020/configure-prometheus-on-a-sub-path-behind-reverse-proxy/ and gateway/ingress.yml

spark-history-server:
  serviceAccount:
    create: false
    name: ${sparkhistoryserviceaccount}
  gcs:
    logDirectory: gs://${bucket_without_gs}/${sparkhistoryname}
    enableGCS: true
    enableIAM: true
  pvc:
    enablePVC: false

  nfs:
    enableExampleNFS: false

  image:
    repository: us-central1-docker.pkg.dev/${project}/${project}/sparkhistory
    tag: ${tag}
    pullPolicy: IfNotPresent

  service:
    type: ClusterIP

  environment:
    SPARK_PUBLIC_DNS: https://${organization}.streamstate.org/sparkhistory/

argo-events:
  namespace: ${controlpanenamespace}

argo-workflows:
  workflow:
    namespace: ${controlpanenamespace} # Specify namespace if workflows run in another namespace than argo. This controls where the service account and RBAC resources will be created.
    serviceAccount:
      create: false # Specifies whether a service account should be created
      annotations: {}
      name: ${argoserviceaccount} # Service account which is used to run workflows
    rbac:
      create: false # adds Role and RoleBinding for the above specified service account to be able to run workflows

  createAggregateRoles: false
  singleNamespace: true
  controller:
    podAnnotations:
      prometheus.io/scrape: "true"
      prometheus.io/path: /metrics
      prometheus.io/port: "9090"
    metricsConfig:
      enabled: true
    clusterWorkflowTemplates:
      # Create a ClusterRole and CRB for the controller to access ClusterWorkflowTemplates.
      enabled: false
    serviceMonitor: # prometheus operator
      enabled: true 
      additionalLabels:
        app: argo
        release: prometheus

  server:
    enabled: true
    # only updates base url of resources on client side,
    # it's expected that a proxy server rewrites the request URL and gets rid of this prefix
    # https://github.com/argoproj/argo-workflows/issues/716#issuecomment-433213190
    baseHref: /ui/ # see gateway/ingress.yml https://github.com/argoproj/argo-workflows/blob/master/docs/argo-server.md#ingress
    clusterWorkflowTemplates:
      # Create a ClusterRole and CRB for the server to access ClusterWorkflowTemplates.
      enabled: false
    
  useDefaultArtifactRepo: true
  artifactRepository:
    # archiveLogs will archive the main container logs as an artifact
    archiveLogs: true
    gcs:
      # todo, probably make this get passed in entirely.  see ./terraform/organization/serviceaccounts/serviceaccounts.tf
      bucket: streamstate-argologs-${organization} 
      keyFormat: "{{workflow.namespace}}/{{workflow.name}}/"




grafana:
  rbac:
    namespaced: true
  service:
    type: ClusterIP
    port: 3000
    targetPort: 3000

  # https://grafana.com/tutorials/run-grafana-behind-a-proxy/
  # gateway/ingress.yml
  grafana.ini:
    auth.anonymous:
        enabled: true
    server:
      server:
      domain: ${organization}.streamstate.org 
      root_url: https://${organization}.streamstate.org/grafana/
      serve_from_sub_path: true
  datasources: 
    datasources.yaml:
      apiVersion: 1
      datasources:
      - name: Prometheus
        type: prometheus
        url: http://prometheus-operated.serviceplane-${organization}.svc.cluster.local:9090
        access: proxy
        isDefault: true

  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: default
          orgId: 1
          folder:
          type: file
          disableDeletion: true
          editable: false
          options:
            path: /var/lib/grafana/dashboards/default
  dashboards:
    default:
      argo:
        json: {{ include "mytpl" . | lower | quote }}




















service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
      - path: /
        backend:
          serviceName: chart-example.local
          servicePort: 80
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
